{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cba487e-8c98-4612-9916-57597ba921e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "c670a204-fb69-4da2-bdc7-9b4410972af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"/Users/tddy/Downloads/ChatExport_2024-09-14/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "820cc6f2-13be-49fa-8525-9fe21b509820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_merge(messages: list, start_idx: int, end_idx: int, timeout: int) -> bool:\n",
    "    first_message, second_to_last_message, last_message = messages[start_idx], messages[end_idx - 1], messages[end_idx]\n",
    "    if last_message[\"ts\"] - second_to_last_message[\"ts\"] > timeout:\n",
    "        return False\n",
    "\n",
    "    if first_message[\"user_id\"] != last_message[\"user_id\"]:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "bf9375c2-bd05-4ff4-a7e0-467cf6adadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_messages(messages: list, start_idx: int, end_idx: int) -> dict:\n",
    "    texts = [messages[idx][\"text\"] for idx in range(start_idx, end_idx)]\n",
    "\n",
    "    merged_message = {}\n",
    "    merged_message[\"user_id\"] = messages[start_idx][\"user_id\"]\n",
    "    merged_message[\"user_name\"] = messages[start_idx][\"user_name\"]\n",
    "    merged_message[\"ts\"] = messages[start_idx][\"ts\"]\n",
    "    merged_message[\"id\"] = messages[start_idx][\"id\"]\n",
    "    merged_message[\"text\"] = \". \".join(texts)\n",
    "\n",
    "    return merged_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "26fd52eb-9adb-47f6-a963-04062dede703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_messages(messages: list, timeout: int) -> list:\n",
    "    start_idx, end_idx = 0, 0\n",
    "    merged_messages = []\n",
    "    while start_idx < len(messages):\n",
    "        end_idx = end_idx + 1\n",
    "        if end_idx == len(messages):\n",
    "            merged_messages.append(merge_messages(messages, start_idx, end_idx))\n",
    "            start_idx = end_idx\n",
    "        else:\n",
    "            start_message, end_message = messages[start_idx], messages[end_idx]\n",
    "            if not check_for_merge(messages, start_idx, end_idx, timeout):\n",
    "                merged_messages.append(merge_messages(messages, start_idx, end_idx))\n",
    "                start_idx = end_idx\n",
    "    return merged_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "5ff878c6-91b4-4330-b981-0c2fd2b2f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_messages(file_name: str, timeout: int=30) -> list:\n",
    "    messages = []\n",
    "    with open(file_name) as file:\n",
    "        data = json.load(file)\n",
    "        file.close()\n",
    "        for record in data[\"messages\"]:\n",
    "            if record[\"type\"] == \"message\" and type(record[\"text\"]) is str and len(record[\"text\"]) != 0:\n",
    "                message = {}\n",
    "                message[\"id\"] = record[\"id\"]\n",
    "                message[\"text\"] = record[\"text\"]\n",
    "                message[\"ts\"] = int(record[\"date_unixtime\"])\n",
    "                message[\"user_id\"] = record[\"from_id\"]\n",
    "                message[\"user_name\"] = record[\"from\"]\n",
    "                messages.append(message)\n",
    "\n",
    "    messages = sorted(messages, key=lambda x: x[\"ts\"])\n",
    "\n",
    "    return merge_consecutive_messages(messages, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "266eb09a-c743-4f86-a8b8-5ec864d6c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = read_messages(DATA_FILE, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "f0e1c13e-0a71-4061-9357-8b940bc6512a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_id': 'user131782652',\n",
       "  'user_name': 'Alexander Sobol',\n",
       "  'ts': 1630613015,\n",
       "  'id': -999010621,\n",
       "  'text': 'Добавьте свята у меня нет его телеги'},\n",
       " {'user_id': 'user131782652',\n",
       "  'user_name': 'Alexander Sobol',\n",
       "  'ts': 1630613634,\n",
       "  'id': -999010617,\n",
       "  'text': 'Чтобы вам было проще с меня 7\\xa0140 (фальцетом)'},\n",
       " {'user_id': 'user131782652',\n",
       "  'user_name': 'Alexander Sobol',\n",
       "  'ts': 1630613786,\n",
       "  'id': -999010615,\n",
       "  'text': 'Блять там в чеке ещё ндс'},\n",
       " {'user_id': 'user237923972',\n",
       "  'user_name': 'Dmitrii Ushanov',\n",
       "  'ts': 1630613814,\n",
       "  'id': -999010614,\n",
       "  'text': 'не саш. это оч много. давай в банке сочтемся. как там с вакансиями, кстати?'},\n",
       " {'user_id': 'user218280715',\n",
       "  'user_name': 'Evgeniya Ponomarenko',\n",
       "  'ts': 1630613844,\n",
       "  'id': -999010610,\n",
       "  'text': 'Можно микрокредит взять до зп?'},\n",
       " {'user_id': 'user278782876',\n",
       "  'user_name': 'Борис Шарчилев',\n",
       "  'ts': 1630613949,\n",
       "  'id': -999010607,\n",
       "  'text': 'Я не хочу платить'},\n",
       " {'user_id': 'user131782652',\n",
       "  'user_name': 'Alexander Sobol',\n",
       "  'ts': 1630614304,\n",
       "  'id': -999010606,\n",
       "  'text': 'Ну охуеть. Думаешь так это работает ?'},\n",
       " {'user_id': 'user237923972',\n",
       "  'user_name': 'Dmitrii Ushanov',\n",
       "  'ts': 1630614354,\n",
       "  'id': -999010604,\n",
       "  'text': 'ну саш. ты из нас единственный трудоучтроенный'},\n",
       " {'user_id': 'user131782652',\n",
       "  'user_name': 'Alexander Sobol',\n",
       "  'ts': 1630614369,\n",
       "  'id': -999010602,\n",
       "  'text': 'Дим ты самый перспективный из нас'},\n",
       " {'user_id': 'user237923972',\n",
       "  'user_name': 'Dmitrii Ushanov',\n",
       "  'ts': 1630614373,\n",
       "  'id': -999010601,\n",
       "  'text': 'и антону сливал'}]"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "67c5daa0-aed0-42c7-9539-a1ca07ca8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset:\n",
    "    def __init__(self, messages: list, max_context_tokens: int=5000, max_context_messages: int=5, gpt_model_name: str=\"gpt-4o\"):\n",
    "        self.messages = messages\n",
    "        \n",
    "        self.max_context_tokens = max_context_tokens\n",
    "        self.max_context_messages = max_context_messages\n",
    "        \n",
    "        self.tokenizer = tiktoken.encoding_for_model(gpt_model_name)\n",
    "   \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.messages)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        context_length = random.randint(1, self.max_context_messages)\n",
    "        bot_message = self.messages[idx]\n",
    "\n",
    "        result = {}\n",
    "        result[\"messages\"] = []\n",
    "        result[\"messages\"].append({\"role\": \"system\", \"content\": \"Продолжи цепочку сообщений в групповом чате наиболее подходящим образом.\"})\n",
    "        context_idx = idx - 1\n",
    "        token_count = 0\n",
    "        while len(result[\"messages\"]) < context_length and context_idx >= 0:\n",
    "            text = messages[context_idx][\"user_name\"] + \": \" + messages[context_idx][\"text\"]\n",
    "            token_count += len(encoding.encode(text))\n",
    "            if token_count > self.max_context_tokens:\n",
    "                break\n",
    "\n",
    "            result[\"messages\"].append({\"role\": \"user\", \"content\": text})\n",
    "            context_idx -= 1\n",
    "\n",
    "        result[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_message[\"text\"], \"weight\": 1})\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_users(self) -> set:\n",
    "        return self.user_to_message_ids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "2a074baf-b104-45f4-a2cf-f4914c43150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset(messages, max_context_tokens=5000, max_context_messages=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "1f584a61-1088-40ef-8364-1f307312a804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'Продолжи цепочку сообщений в групповом чате наиболее подходящим образом.'},\n",
       "  {'role': 'user', 'content': 'Dmitrii Ushanov: овербукинг на позицию'},\n",
       "  {'role': 'user', 'content': 'Борис Шарчилев: Мои позиции ослабляются'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Svyatoslav Yushin: Понятно почему на кухне больше черешни нет. Уже тогда всё было решено...'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Dmitrii Ushanov: не забудь подчеркнуть сочетание рубашки и штанов'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Борис Шарчилев: Мне кстати сео в слаке писал, но так и не поставил'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Evgeniya Ponomarenko: Ахаха. Про отпуск так и не спросили, завтра спрошу сео'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Dmitrii Ushanov: и вопросы оттуда задаете!!!111'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Svyatoslav Yushin: Поездка будет быстрой, простой поездка не будет'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Evgeniya Ponomarenko: Ну мы люди простые. В свою жопу поехали'},\n",
       "  {'role': 'user', 'content': 'Dmitrii Ushanov: это вы в балашиху едите'},\n",
       "  {'role': 'user', 'content': 'Evgeniya Ponomarenko: Без шлема'},\n",
       "  {'role': 'user', 'content': 'Dmitrii Ushanov: я уже дома, вообще-тг'},\n",
       "  {'role': 'assistant', 'content': 'У меня в календаре стоит!', 'weight': 1}]}"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "a50bebd9-b307-4a34-ad54-5666148aff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FILE = \"/Users/tddy/Downloads/ChatExport_2024-09-14/train_dataset_large\"\n",
    "TEST_DATASET_FILE = \"/Users/tddy/Downloads/ChatExport_2024-09-14/test_dataset_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "77e6a1dd-06f0-460a-902d-b3d53b81fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(samples, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for sample in samples:\n",
    "        for message in sample[\"messages\"]:\n",
    "            num_tokens += 4\n",
    "            for key, value in message.items():\n",
    "                if key != \"weight\":\n",
    "                    num_tokens += len(encoding.encode(value))\n",
    "        num_tokens += 2\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "a788d83d-31a3-4754-90b1-780c5036d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataset: ChatDataset, train_output_path: str, test_output_path:str, sample_rate: float, test_share: float=0.1):\n",
    "    split_idx = len(dataset) - int(len(dataset) * test_share)\n",
    "\n",
    "    samples = []\n",
    "    for idx in range(0, split_idx):\n",
    "        if random.random() < sample_rate:\n",
    "            sample = dataset[idx]\n",
    "            samples.append(sample)  \n",
    "    print(\"Train tokens: \" + str(num_tokens_from_messages(samples)))\n",
    "\n",
    "    with open(train_output_path, \"w\") as file:\n",
    "        file.write(\"\\n\".join([json.dumps(sample, ensure_ascii=False) for sample in samples]))\n",
    "\n",
    "    samples = []\n",
    "    for idx in range(split_idx, len(dataset)):\n",
    "        if random.random() < sample_rate:\n",
    "            sample = dataset[idx]\n",
    "            samples.append(sample)\n",
    "    print(\"Test tokens: \" + str(num_tokens_from_messages(samples)))\n",
    "\n",
    "    with open(test_output_path, \"w\") as file:\n",
    "        file.write(\"\\n\".join([json.dumps(sample, ensure_ascii=False) for sample in samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "a7981020-717a-4857-8290-ff2e6faf6897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens: 15269733\n",
      "Test tokens: 730484\n"
     ]
    }
   ],
   "source": [
    "split_train_test(dataset, TRAIN_DATASET_FILE, TEST_DATASET_FILE, 0.15, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4081199-de25-4c86-8d75-93ade85b7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "ORGANIZATION_ID = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0a42de-4e84-42d7-b2ed-0abfb273c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY, organization=ORGANIZATION_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "bf25ef1a-53d9-4346-9370-7c14dd90c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = client.files.create(\n",
    "  file=open(TRAIN_DATASET_FILE, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "366f1ca1-e94a-4657-b378-aeb887f169cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-o2MN2ORowM72Uy0gJE1tBQxW', bytes=81570505, created_at=1727028465, filename='train_dataset_large', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "30119750-572b-425d-bfc5-9d376685d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = client.files.create(\n",
    "  file=open(TEST_DATASET_FILE, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "8d291c35-d044-464b-83a4-4f34e4235260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-ukU9i6ipCenAPzPHX7L6NWX9', bytes=3988526, created_at=1727028281, filename='test_dataset_large', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "9c83a3b2-64d7-4735-b3cc-7fb3e0d2c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-o2MN2ORowM72Uy0gJE1tBQxW\",\n",
    "    validation_file=\"file-ukU9i6ipCenAPzPHX7L6NWX9\",\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    hyperparameters={\"n_epochs\":2, \"batch_size\": 64, \"learning_rate_multiplier\":0.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "fa8f2ed7-b6b2-4b30-bc1b-9569c58e0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-bjhoGI05AJ0Q7x6u1VLsnvEI', created_at=1727028531, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size=64, learning_rate_multiplier=0.1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-vHh861blWyZBvSmugtU4QmIU', result_files=[], seed=1079764368, status='validating_files', trained_tokens=None, training_file='file-o2MN2ORowM72Uy0gJE1tBQxW', validation_file='file-ukU9i6ipCenAPzPHX7L6NWX9', estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a3c27c-9765-4b8f-9c53-3ba247e3d513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-bjhoGI05AJ0Q7x6u1VLsnvEI', created_at=1727028531, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size=64, learning_rate_multiplier=0.1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-vHh861blWyZBvSmugtU4QmIU', result_files=[], seed=1079764368, status='validating_files', trained_tokens=None, training_file='file-o2MN2ORowM72Uy0gJE1tBQxW', validation_file='file-ukU9i6ipCenAPzPHX7L6NWX9', estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-bjhoGI05AJ0Q7x6u1VLsnvEI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "d31d2c4b-f6b0-4752-b3e6-8f5c1b3a5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::AAMiVZbj\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Продолжи цепочку сообщений в групповом чате наиболее подходящим образом.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Evgeniya Ponomarenko: Уверена кстати что нихуя не сделаете из-за Саши\"},\n",
    "    {\"role\": \"user\", \"content\": \"Evgeniya Ponomarenko: Он затянет в болото, а потом бросит, как все свои увлечения\"},\n",
    "    {\"role\": \"user\", \"content\": \"Alexander Sobol: Ого какой гной\"},\n",
    "    {\"role\": \"user\", \"content\": \"Evgeniya Ponomarenko: без гавна\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: ого, а почему заорала?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: это пока похоже на развитие событий\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: но я нашел саше мотивацию\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: такой же стартап делает витекv\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: так что пока вроде он заинтересован\"},\n",
    "    {\"role\": \"user\", \"content\": \"Evgeniya Ponomarenko: Типа его конкуренция сможешь мотивировать с дивана встать?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: не, типа прорабатываем стратегию второго шанса\"},\n",
    "    {\"role\": \"user\", \"content\": \"Evgeniya Ponomarenko: Ну нужно сильно мотивировать\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: так а че саша совсем стал не дееспособный?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dmitrii Ushanov: да он только на диване может лежать и ничего не делать\"},\n",
    "    {\"role\": \"user\", \"content\": \"Alexander Sobol: виталик, как дела в буках?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "7e468718-2aa9-4368-aab3-ca8b69b6ce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AAFQIfy2HJvSemn26uDTMmQG2SZDw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Vitaly Grigorash. Ну хз. Мы в плюсах', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727005930, model='ft:gpt-4o-2024-08-06:personal::AAFLBKbW', object='chat.completion', service_tier=None, system_fingerprint='fp_845b2ae0fe', usage=CompletionUsage(completion_tokens=14, prompt_tokens=45, total_tokens=59, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
